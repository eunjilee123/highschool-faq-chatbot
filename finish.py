

## streamlit ê´€ë ¨ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°
import streamlit as st
from streamlit.runtime.uploaded_file_manager import UploadedFile


from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents.base import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain_core.runnables import Runnable
from langchain.schema.output_parser import StrOutputParser
from langchain_community.document_loaders import PyMuPDFLoader
from typing import List
import os
import fitz  # PyMuPDF
import re

## í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
from dotenv import load_dotenv,dotenv_values
load_dotenv()



############################### 1ë‹¨ê³„ : PDF ë¬¸ì„œë¥¼ ë²¡í„°DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë“¤ ##########################

## 1: ì„ì‹œí´ë”ì— íŒŒì¼ ì €ì¥
def save_uploadedfile(uploadedfile: UploadedFile) -> str : 
    temp_dir = "PDF_ì„ì‹œí´ë”"
    if not os.path.exists(temp_dir):
        os.makedirs(temp_dir)
    file_path = os.path.join(temp_dir, uploadedfile.name)
    with open(file_path, "wb") as f:
        f.write(uploadedfile.read()) 
    return file_path

## 2: ì €ì¥ëœ PDF íŒŒì¼ì„ Documentë¡œ ë³€í™˜
def pdf_to_documents(pdf_path:str) -> List[Document]:
    documents = []
    loader = PyMuPDFLoader(pdf_path)
    doc = loader.load()
    for d in doc:
        d.metadata['file_path'] = pdf_path
    documents.extend(doc)
    return documents

## 3: Documentë¥¼ ë” ì‘ì€ documentë¡œ ë³€í™˜
def chunk_documents(documents: List[Document]) -> List[Document]:
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    return text_splitter.split_documents(documents)

## 4: Documentë¥¼ ë²¡í„°DBë¡œ ì €ì¥
import tiktoken

enc = tiktoken.encoding_for_model("text-embedding-3-small")

def get_token_count(text: str) -> int:
    return len(enc.encode(text))

def chunk_documents_by_tokens(documents, max_tokens=300000):
    chunks = []
    current_chunk = []
    current_token_count = 0

    for doc in documents:
        token_count = get_token_count(doc.page_content)
        if current_token_count + token_count > max_tokens:
            chunks.append(current_chunk)
            current_chunk = [doc]
            current_token_count = token_count
        else:
            current_chunk.append(doc)
            current_token_count += token_count

    if current_chunk:
        chunks.append(current_chunk)

    return chunks

def save_to_vector_store(documents: List[Document]) -> None:
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    chunks = chunk_documents_by_tokens(documents, max_tokens=300000)
    vector_store = None

    for chunk in chunks:
        current_index = FAISS.from_documents(chunk, embedding=embeddings)
        if vector_store is None:
            vector_store = current_index
        else:
            vector_store.merge_from(current_index)

    vector_store.save_local("faiss_index")



############################### 2ë‹¨ê³„ : RAG ê¸°ëŠ¥ êµ¬í˜„ê³¼ ê´€ë ¨ëœ í•¨ìˆ˜ë“¤ ##########################


## ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ RAG ì²˜ë¦¬
@st.cache_data
def process_question(user_question):


    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    ## ë²¡í„° DB í˜¸ì¶œ
    new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)

    ## ê´€ë ¨ ë¬¸ì„œ 3ê°œë¥¼ í˜¸ì¶œí•˜ëŠ” Retriever ìƒì„±
    retriever = new_db.as_retriever(search_kwargs={"k": 3})
    ## ì‚¬ìš©ì ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ë¬¸ì„œ 3ê°œ ê²€ìƒ‰ 
    retrieve_docs : List[Document] = retriever.invoke(user_question)

    ## RAG ì²´ì¸ ì„ ì–¸
    chain = get_rag_chain()
    ## ì§ˆë¬¸ê³¼ ë¬¸ë§¥ì„ ë„£ì–´ì„œ ì²´ì¸ ê²°ê³¼ í˜¸ì¶œ
    response = chain.invoke({"question": user_question, "context": retrieve_docs})

    return response, retrieve_docs



def get_rag_chain() -> Runnable:
    template = """
    ë‹¤ìŒì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•´ì„œ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜
    - ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì„ í•´ì¤˜
    - ê°„ê²°í•˜ê²Œ 5ì¤„ ì´ë‚´ë¡œ í•´ì¤˜
    - ê³§ë°”ë¡œ ì‘ë‹µê²°ê³¼ë¥¼ ë§í•´ì¤˜

    ì»¨í…ìŠ¤íŠ¸ : {context}

    ì§ˆë¬¸: {question}

    ì‘ë‹µ:"""

    custom_rag_prompt = PromptTemplate.from_template(template)
    model = ChatOpenAI(model="gpt-4o-mini")

    return custom_rag_prompt | model | StrOutputParser()



############################### 3ë‹¨ê³„ : ì‘ë‹µê²°ê³¼ì™€ ë¬¸ì„œë¥¼ í•¨ê»˜ ë³´ë„ë¡ ë„ì™€ì£¼ëŠ” í•¨ìˆ˜ ##########################
@st.cache_data(show_spinner=False)
def convert_pdf_to_images(pdf_path: str, dpi: int = 250) -> List[str]:
    doc = fitz.open(pdf_path)  # ë¬¸ì„œ ì—´ê¸°
    image_paths = []
    
    # ì´ë¯¸ì§€ ì €ì¥ìš© í´ë” ìƒì„±
    output_folder = "PDF_ì´ë¯¸ì§€"
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    for page_num in range(len(doc)):  #  ê° í˜ì´ì§€ë¥¼ ìˆœíšŒ
        page = doc.load_page(page_num)  # í˜ì´ì§€ ë¡œë“œ

        zoom = dpi / 72  # 72ì´ ë””í´íŠ¸ DPI
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat) # type: ignore

        image_path = os.path.join(output_folder, f"page_{page_num + 1}.png")  # í˜ì´ì§€ ì´ë¯¸ì§€ ì €ì¥ page_1.png, page_2.png, etc.
        pix.save(image_path)  # PNG í˜•íƒœë¡œ ì €ì¥
        image_paths.append(image_path)  # ê²½ë¡œë¥¼ ì €ì¥
        
    return image_paths

def display_pdf_page(image_path: str, page_number: int) -> None:
    image_bytes = open(image_path, "rb").read()  # íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì¸ì‹
    st.image(image_bytes, caption=f"Page {page_number}", output_format="PNG", width=600)


def natural_sort_key(s):
    return [int(text) if text.isdigit() else text for text in re.split(r'(\d+)', s)]

import streamlit as st
import os  # osë„ í•„ìš”í•˜ë‹ˆê¹Œ ì¶”ê°€
# ë‹¤ë¥¸ í•„ìš”í•œ importë„ ì—¬ê¸°ì—

# âœ… set_page_configëŠ” ê°€ì¥ ìœ„ì—ì„œ ë‹¨ í•œ ë²ˆë§Œ!
st.set_page_config(page_title="ê³ êµí•™ì ì œ FAQ ì±—ë´‡", layout="wide")

# ìƒë‹¨ ì•ˆë‚´ ë©”ì‹œì§€
st.markdown("""
<style>
.notice-box {
    padding: 1em;
    background-color: #fff3cd;
    border-left: 6px solid #ffa500;
    color: #856404;
    border-radius: 5px;
    margin-bottom: 1em;
    font-weight: 500;
}
</style>

<div class="notice-box">
    âš ï¸ ì±—ë´‡ ë‹µë³€ì´ ë¶€ì¡±í•  ìˆ˜ ìˆì–´ìš”!<br>
    ğŸ“„ ì•„ë˜ ìš”ì•½ëœ <strong>PDF ì´ë¯¸ì§€ ìë£Œ</strong>ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”.
</div>
""", unsafe_allow_html=True)











def main():
    
    left_column, right_column = st.columns([1, 1])
    with left_column:
        st.header("ê³ êµí•™ì ì œ FAQ ì±—ë´‡")

        user_question = st.text_input("PDF ë¬¸ì„œì— ëŒ€í•´ì„œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”",
                                        placeholder="ìœ¤ë¦¬ì™€ ì‚¬ìƒ ì„±ì  ì‚°ì¶œì— ëŒ€í•´ ì•Œë ¤ì¤˜")

        if user_question:
            response, context = process_question(user_question)
            st.write(response)
            i = 0 
            for document in context:
                with st.expander("ê´€ë ¨ ë¬¸ì„œ"):
                    st.write(document.page_content)
                    file_path = document.metadata.get('source', '')
                    page_number = document.metadata.get('page', 0) + 1
                    button_key =f"link_{file_path}_{page_number}_{i}"
                    reference_button = st.button(f"ğŸ” {os.path.basename(file_path)} pg.{page_number}", key=button_key)
                    if reference_button:
                        st.session_state.page_number = str(page_number)
                    i = i + 1
    with right_column:
        # page_number í˜¸ì¶œ
        page_number = st.session_state.get('page_number')
        if page_number:
            page_number = int(page_number)
            image_folder = "pdf_ì´ë¯¸ì§€"
            images = sorted(os.listdir(image_folder), key=natural_sort_key)
            print(images)
            image_paths = [os.path.join(image_folder, image) for image in images]
            print(page_number)
            print(image_paths[page_number - 1])
            display_pdf_page(image_paths[page_number - 1], page_number)


if __name__ == "__main__":
    main()

# ê³ ì • PDF ê²½ë¡œ ì§€ì •
# ê³ ì • PDF ê²½ë¡œ ì§€ì • (Streamlit Cloudì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ìƒëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •)

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
import os
from langchain_community.document_loaders import PyMuPDFLoader

def pdf_to_documents(pdf_path):
    if not os.path.isfile(pdf_path):
        raise ValueError(f"File path {pdf_path} is not a valid file.")
    loader = PyMuPDFLoader(pdf_path)
    return loader.load()

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
pdf_path = os.path.join(CURRENT_DIR, "public", "2022ê°œì • ê³ ë“±í•™êµ ê³¼ëª© ì„ íƒ ì•ˆë‚´ìë£Œ-ê²½ê¸°ë„êµìœ¡ì²­.pdf")

pdf_document = pdf_to_documents(pdf_path)









 # ì˜ˆì‹œ íŒŒì¼ëª…, ë³¸ì¸ì´ ë„£ì€ íŒŒì¼ëª…ìœ¼ë¡œ ìˆ˜ì •

# PDFë¥¼ ë¬¸ì„œë¡œ ë³€í™˜ í›„ ë²¡í„°DB ì €ì¥ (ìµœì´ˆ ì‹¤í–‰ ì‹œë§Œ í•„ìš”)
with st.spinner("PDF ë¬¸ì„œ ë¡œë“œ ì¤‘..."):
    pdf_document = pdf_to_documents(pdf_path)
    smaller_documents = chunk_documents(pdf_document)
    save_to_vector_store(smaller_documents)

# PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•´ì„œ ì„¸ì…˜ ìƒíƒœë¡œ ì„ì‹œ ì €ì¥
with st.spinner("PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ ì¤‘..."):
    images = convert_pdf_to_images(pdf_path)
    st.session_state.images = images


import subprocess
import time
import requests

# ngrok ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œë¡œ)
subprocess.Popen(["ngrok", "http", "8501"])

# ngrok ì—°ê²° ê¸°ë‹¤ë¦¬ê¸°
time.sleep(5)

# ngrok ì£¼ì†Œ ê°€ì ¸ì˜¤ê¸°
def get_ngrok_url():
    res = requests.get("http://127.0.0.1:4040/api/tunnels")
    tunnels = res.json()["tunnels"]
    for tunnel in tunnels:
        if tunnel["proto"] == "https":
            return tunnel["public_url"]
    return None

# ë””ìŠ¤ì½”ë“œ ì „ì†¡
def send_to_discord(url):
    webhook_url = "https://discord.com/api/webhooks/..."  # ë„ˆì˜ webhook
    data = {"content": f"ğŸŸ¢ ìƒˆë¡œìš´ ngrok ì£¼ì†Œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤:\n{url}"}
    requests.post(webhook_url, json=data)

url = get_ngrok_url()
if url:
    send_to_discord(url)
    print("âœ… ìë™ ì „ì†¡ ì™„ë£Œ!")
else:
    print("âŒ ngrok ì£¼ì†Œë¥¼ ëª» ì°¾ì•˜ì–´ìš”.")
